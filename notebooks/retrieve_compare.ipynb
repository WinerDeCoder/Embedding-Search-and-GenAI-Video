{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_path = os.path.abspath(\"..\")  # Get absolute path of parent directory\n",
    "if parent_path not in sys.path:  \n",
    "    sys.path.append(parent_path)  # Add only if it's not already there\n",
    "    \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "import openai\n",
    "\n",
    "from src.models.chromadb_functions import *  \n",
    "from src.models.gpt_models import  correct_text_with_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   no                    base_question                 answer  \\\n",
      "0   1   Tại sao cần bón phân cho cây ?        Để cây tươi tốt   \n",
      "1   2  Cây nhãn chăm sóc như thế nào ?  Bón phân thường xuyên   \n",
      "\n",
      "                                    variant_question  \n",
      "0  Lí do cần bón phân cho cây \\nTại sao cây cần p...  \n",
      "1  Chăm sóc cây nhãn ra sao ?\\nLàm sao chăm sóc c...  \n",
      "Excel Length:  2\n"
     ]
    }
   ],
   "source": [
    "question_answer_df = pd.read_excel(\"../data/question_answer/QA.xlsx\")\n",
    "\n",
    "print(question_answer_df)\n",
    "\n",
    "print(\"Excel Length: \", len(question_answer_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ChromaDB Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_path     = \"../data/vector_database\"\n",
    "collection_name     = os.getenv(\"CHROMADB_COLLECTION_NAME\")\n",
    "embedding_func      = define_embedding_function( api_key = os.getenv(\"OPENAI_API_KEY\"), model_name = os.getenv(\"EMBEDDING_MODEL\"))\n",
    "similarity_method   = os.getenv(\"SIMILARITY_METHOD\")\n",
    "\n",
    "chromadb_collection = get_chroma_collection(collection_path, collection_name, embedding_func, similarity_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through variant question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process question:  Tại sao cần bón phân cho cây ?\n",
      "    Variant question:  Lí do cần bón phân cho cây \n",
      "        Passed\n",
      "    Variant question:  Tại sao cây cần phân bón ?\n",
      "        Passed\n",
      "    Variant question:  Taij saoo bons phân cho caay\n",
      "        Passed\n",
      "  Accuracy pass:  1.0\n",
      "----------------------------\n",
      "Process question:  Cây nhãn chăm sóc như thế nào ?\n",
      "    Variant question:  Chăm sóc cây nhãn ra sao ?\n",
      "        Passed\n",
      "    Variant question:  Làm sao chăm sóc cây nhãn cho tốt \n",
      "        Passed\n",
      "    Variant question:  Khi chăm cây nhãn caanff phải làm chi \n",
      "        Passed\n",
      "  Accuracy pass:  1.0\n",
      "----------------------------\n",
      "Total Summary:  1.0\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "\n",
    "for index, row in question_answer_df.iterrows():\n",
    "    question_index  = row[\"no\"]\n",
    "    base_question   = row[\"base_question\"]\n",
    "    variant_question_list   = row[\"variant_question\"].split(\"\\n\")\n",
    "    \n",
    "    print(\"Process question: \", base_question)\n",
    "    \n",
    "    match_count = 0\n",
    "    \n",
    "    for quest in variant_question_list:\n",
    "        \n",
    "        print(\"    Variant question: \", quest)\n",
    "        # Fix question first\n",
    "        fixed_quest = correct_text_with_gpt(input_text = quest)\n",
    "        \n",
    "        results = chromadb_collection.query(\n",
    "            query_texts=[fixed_quest], # Chroma will embed this for you\n",
    "            n_results=1 # how many results to return\n",
    "        )\n",
    "        \n",
    "        if results[\"documents\"][0][0] == base_question:\n",
    "            match_count +=1\n",
    "            print(\"        Passed\")\n",
    "        else:\n",
    "            print(\"        Failed\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    accuracy = match_count/len(variant_question_list)\n",
    "    if accuracy >= 0.8:\n",
    "        total_count += 1\n",
    "        print(\"  Accuracy pass: \", accuracy)\n",
    "    else:\n",
    "        print(\"  Accuracy failed: \", accuracy)\n",
    "    \n",
    "    print(\"----------------------------\")\n",
    "        \n",
    "        \n",
    "print(\"Total Summary: \", total_count/len(question_answer_df))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
